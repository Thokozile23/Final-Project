# Final-Project

## Nice visuals to illustrate your main concepts and why this project is important for businesses. 

## Authors:
- **Elaina Longjohn**  
  GitHub:https://github.com/elongjohn

- **Mills Becouvarakis**  
  GitHub: https://github.com/author2
  
- **Shields Riggs**  
  GitHub: https://github.com/author1

- **Thokozile Munthali**  
  GitHub: https://github.com/author2

## Project Scope: Be as specific as possible with the scope of your project (which should be as narrowly focused as possible.) 
Our project examines the negative effects of feedback loops in recommender systems. A feedback loop is a cycle where a user’s interactions with recommended items influence their future recommendations. This happens because every action a user takes—whether it's clicking, rating, or engaging with content—gets recorded in their profile, which then leads to more similar recommendations in the future.

The negative impacts of these feedback loops are significant, particularly the amplification of popularity bias. In this scenario, the preferences of the majority overpower those of minority groups, causing the recommender system to focus heavily on a narrow set of popular items. This limits both the diversity of recommendations and the potential for users to discover new, lesser-known content.

As a result, minority preferences are often drowned out by the mainstream, making it harder for niche or emerging products to get noticed. Through our project, we aim to address this issue by finding a way to reduce popularity bias and create a more level playing field for all products, free from the inherent biases built into recommender systems.

## Website: Popularity Bias & Feedback Loops Simulation
https://claude.site/artifacts/79270026-7cfb-4106-a677-2b3b898d03d5


## Project Details: With logical organization and clear but concise writeups. 

## What's next? Help us envision future developments and concerns. 

## Responsible AI considerations: Recommender System Biases
![image](https://github.com/user-attachments/assets/ea0dde89-b003-4d35-8ee8-c1c536f815d4)

Understanding the biases present in recommender systems (RSs) is crucial, as these biases can significantly impact the fairness, accuracy, and trustworthiness of recommendations. The biases within RSs can be categorized into four main types: data biases, cognitive biases, position/presentation biases, and algorithmic/model biases.

- Data Bias:
Data biases occur when the training data used by the recommender system is unbalanced or not fully representative of the entire user base. For example, certain demographic groups may be underrepresented, leading to recommendations that fail to reflect the diversity of users or perpetuate existing inequalities.

- Coginitive Bias:
Cognitive biases are influenced by human mental shortcuts or heuristics, which can affect how users interact with the system. Examples include the anchoring effect, where users rely too heavily on the first piece of information they encounter, or the recency effect, which may cause users to favor items that are more recent rather than more relevant.

- Position/Presentation Bias:
Position or presentation biases arise from the way recommendations are displayed to users. Items placed at the top of the list, for example, are more likely to be selected, regardless of their actual relevance to the user. This form of bias is often unintentional but can significantly skew the user experience.

- Algorithmic/Model Bias
Algorithmic or model biases are embedded in the recommendation algorithms themselves, often due to the way models are trained or the data they use. These biases can amplify existing stereotypes or reinforce behaviors by overemphasizing certain patterns in user data, such as preferences based on past behaviors or demographic factors.



## References:
https://research.ebsco.com/c/bq4orh/viewer/pdf/nqcpkx6jdv
